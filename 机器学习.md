# 机器学习算法(1):基于逻辑回归的分类预测
## 1 逻辑回归的介绍与应用
### 1.1 逻辑回归的介绍
逻辑回归是一个**分类**模型，广泛运用于各个领域之中。
对于逻辑回归，最突出的两个点就是：**模型简单**、**模型的可解释性强**

逻辑回归的优劣如下：
* 优点：实现简单，易于理解和实现；计算代价不高，速度快，存储资源低。
* 缺点：容易欠拟合，分类精度可能不高

### 2 逻辑回归的应用
逻辑回归模型广泛用在各个领域：
* 创伤和损伤严重度评分。
* 使用逻辑回归基于观察到的患者特征分析预测发生特定疾病的风险。
* 用于预测在给定过程中，系统或产品的故障的可能性。
* 预测客户购买产品或终止订购的倾向等。
* 预测一个人先择进入劳动力市场的可能性。
* 预测房主拖欠抵押贷款的可能性。

逻辑回归模型同样是很多**分类**算法的基础组件！！
* 分类任务中基于GBDT算法+LR逻辑回归实现的信用卡交易反诈骗。

由于其==本质==是一个线性的分类器，所以对于较复杂的数据情况，很多时候就会去拿逻辑回归模型做一些任务尝试的==基线==（基础水平）

## 3 算法实战
### 3.1 Demo实战
#### Step1:导入库函数
```python
#基础数据库
import numpy as np

#导入数据可视化库
import matplotlib.pyplot as plt

#导入逻辑回归模型
from sklearn.linear_model import LogisticRegression
```
#### Step2:训练模型
```python
##构造数据集
x_fearures = np.array([[-1, -2], [-2, -1], [-3, -2], [1, 3], [2, 1], [3, 2]])
y_label=np.array([0,0,0,1,1,1])

##调用逻辑回归模型
model = LogisticRegression()

##用逻辑回归模型拟合构造的数据集
model.fit(x_fearures,y_label)
##最后的拟合方程为:y=w0+w1*x1+w2*x2
```

#### Step3:模型参数查看
```python
#查看对应模型的w值
print('the weight of Logistic Regression:',model.coef_)

#查看对应的w0值（常数项）
print('the intercept(w0) of Logistic Regression:',model.intercept_)
```

#### Step4:模型可视化
```python
#可视化的数据样本点
plt.figure()
plt.scatter(x_fearures[:,0],x_fearures[:,1],c=y_label,s=50,cmap='viridis')
plt.title('Dataset')
plt.show()
```

```python
#可视化决策边界
plt.figure()
plt.scatter(x_fearures[:,0],x_fearures[:,1],c=y_label,s=50,cmap='viridis')
plt.title('Dataset')

nx,ny=200,100
x_min,x_max=plt.xlim()
y_min,y_max=plt.ylim()
x_grid,y_grid = np.meshgrid(np.linspace(x_min,x_max,nx),np.linspace(y_min,y_max,ny))

z_proba = model.predict_proba(np.c_[x_grid.revel(),y_grid.ravel()])
z_proba = z_proba[:,1].reshape(x_grid.shape)
plt.contour(x_grid,y_grid.z_proba,[0.5],linewidths=2,colors='blue')

plt.show()
```